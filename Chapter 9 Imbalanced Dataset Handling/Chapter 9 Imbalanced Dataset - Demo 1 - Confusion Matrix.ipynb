{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-tsunami",
   "metadata": {},
   "source": [
    "- Precision: Thước đo độ chính xác của phân loại.\n",
    "- Recall: Thước đo tính đầy đủ của phân loại\n",
    "- F1 Score (F-score): Kết hợp precision và recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic[['survived','pclass','fare']] # dùng pclass, fare --> dự đoán cho sống/chết\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic, x='survived');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['pclass','fare']]\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['y_predict'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[y!=y_predict].shape[0] # số trường hợp dự đoán sai là 286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[y==y_predict].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y) # tỉ lệ số dự đoán đúng/ tổng số quan sát (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[y==y_predict].shape[0]/titanic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_predict) # cột: dự đoán; dòng: thực tế; class 0: chết; class 1: sống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# số hành khách chết là : 469+80=549\n",
    "# số hành khách sống là: 206+136=342\n",
    "# số dự đoán đúng cho sông: 136 (342)\n",
    "# số dự đoán đúng cho chết: 469 (549)\n",
    "# recall, 0: 469/(469+80)) # 80 trường hợp dự đoán sai là sống (đi qua nhà hàng xóm)\n",
    "# precision, 0: 469/(469+206) (hàng xóm vào nhà mình) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N: negative ~ 0; P: positive ~ 1\n",
    "# T: true; F: false\n",
    "TN = 469 # dự đoán đúng trường hợp 0\n",
    "TP = 136 # dự đoán đúng trường hợp 1\n",
    "FP = 80 # dự đoán sai: thực tế là 0 ==> dự đoán là 1\n",
    "FN = 206 # dự đoán sai: thực tế là 1 ==> dự đoán là 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precison\n",
    "p_0 = TN/(TN+FN)\n",
    "p_1 = TP/(TP+FP)\n",
    "p_0, p_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "r_0 = TN/(TN+FP)\n",
    "r_1 = TP/(TP+FN)\n",
    "r_0, r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cho nhận xét:\n",
    "# - class 0: \n",
    "# + precision trung bình (thước đo tính chính xác) ==> có chứa khá nhiều những điểm không thuộc class 0\n",
    "# + recall cao (thước đo tính đầy đủ) ==> dự đoán khá chính xác về 1 điểm thuộc về class 0\n",
    "# - class 1: precision và recall đều thấp ==> mô hình xử lý kém đối với class 1\n",
    "# tùy theo yêu cầu của bài toán ==> điều chỉnh precision, recall !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-escape",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
